{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 8 Reading Journal\n",
    "\n",
    "Read _Think Python_, [Chapter 9](http://greenteapress.com/thinkpython2/html/thinkpython2010.html), [13](http://www.greenteapress.com/thinkpython2/html/thinkpython2014.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Chapter 9](http://greenteapress.com/thinkpython2/html/thinkpython2010.html) Case study: word play\n",
    "\n",
    "Download the word list for this chapter from [http://thinkpython2.com/code/words.txt](http://thinkpython2.com/code/words.txt) and save it in your ReadingJournal folder. You can then run the test code below to verify you've got the word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word #0: aa\n",
      "Word #1: aah\n"
     ]
    }
   ],
   "source": [
    "import doctest\n",
    "# Quick test: open 'words.txt' in the current folder and print the first couple entries (\"aa\", \"aah\")\n",
    "fp = open(\"words.txt\")\n",
    "for i in range(2):\n",
    "    word = fp.readline().strip()\n",
    "    print(\"Word #{num}:\".format(num=i), word)\n",
    "fp.close()  # Close the file when we're done with it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encapsulate this behavior into a helper function to use with the rest of the exercises.\n",
    "\n",
    "In this function we use the Python `with` statement to open the file for us. We'll learn more about exactly what this does when we talk about Exceptions, but for now it's enough to say that it opens the file for us and closes it automatically at the end of the `with` block.\n",
    "\n",
    "If you're interested, you can read more about techniques for [reading and writing files](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pythonic\n"
     ]
    }
   ],
   "source": [
    "def get_lines(filename):\n",
    "    \"\"\"\n",
    "    Read all lines from `filename` and return a list of strings, \n",
    "    one per line, with whitespace stripped from the ends.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            # Remove whitespace (or do whatever other processing you like)\n",
    "            processed_line = line.strip()\n",
    "            lines.append(processed_line)\n",
    "            \n",
    "    return lines\n",
    "\n",
    "# Test get_lines helper function by reading word list\n",
    "word_list = get_lines(\"words.txt\")\n",
    "print(word_list[78835])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 9.1\n",
    "\n",
    "Complete the `longer_than` function below and test it by finding long words in the word list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longer_than(word, threshold):\n",
    "    \"\"\"\n",
    "    Return True if 'word' is longer than 'threshold'\n",
    "    \n",
    "    >>> longer_than(\"python\", 15)\n",
    "    False\n",
    "    >>> longer_than(\"documentation\", 6)\n",
    "    True\n",
    "    \"\"\"\n",
    "    if len(word) > threshold:\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "doctest.run_docstring_examples(longer_than, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['counterdemonstrations', 'hyperaggressivenesses', 'microminiaturizations']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for long words by using your helper function in a list comprehension\n",
    "[ word for word in get_lines(\"words.txt\") if longer_than(word, 20) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 9.4\n",
    "\n",
    "Write a function named `uses_only` that takes a word and a string of letters, and that returns `True` if the word contains only letters in the allowed string. Can you make a sentence using only the letters \"acefhlo\"? Other than “Hoe alfalfa?”\n",
    "\n",
    "_Note_: If you're stuck you may want to try Exercise 2 first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uses_only(word, allowed):\n",
    "    \"\"\"\n",
    "    Return True if 'word' contains only letters in 'allowed' string, False otherwise.\n",
    "    \n",
    "    >>> uses_only(\"software\", \"code\")\n",
    "    False\n",
    "    >>> uses_only(\"banana\", \"ban\")\n",
    "    True\n",
    "    \"\"\"\n",
    "    d = dict()\n",
    "    for letter in allowed:\n",
    "        d[letter] = d.get(letter, 1)\n",
    "    for letter in word:\n",
    "        if d.get(letter,0)== 0:\n",
    "            return False\n",
    "    return True\n",
    "doctest.run_docstring_examples(uses_only, globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 9.7\n",
    "\n",
    "This question is based on a Puzzler that was broadcast on the radio program [Car Talk](http://www.cartalk.com/content/puzzlers):\n",
    "\n",
    "> Give me a word with three consecutive double letters. I’ll give you a couple of words that almost qualify, but don’t. For example, the word committee, c-o-m-m-i-t-t-e-e. It would be great except for the ‘i’ that sneaks in there. Or Mississippi: M-i-s-s-i-s-s-i-p-p-i. If you could take out those i’s it would work. But there is a word that has three consecutive pairs of letters and to the best of my knowledge this may be the only word. Of course there are probably 500 more but I can only think of one. What is the word? \n",
    "\n",
    "Write a program to find it. Try on your own, but if you get stuck you can review Allen's solution: http://thinkpython2.com/code/cartalk1.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triple_double():\n",
    "    \"\"\"Reads a word list and prints words with triple double letters.\"\"\"\n",
    "    word_list = open('words.txt')\n",
    "    for line in word_list:\n",
    "        word = line.split()\n",
    "        if have_three_consecutive_letters(word):\n",
    "            print(word)\n",
    "def have_three_consecutive_letters(word):\n",
    "    \"\"\"\n",
    "    >>> have_three_consecutive_letters(\"xaaabbcc\")\n",
    "    True\n",
    "    >>> have_three_consecutive_letters(\"asssfeccess\")\n",
    "    False\n",
    "    \"\"\"\n",
    "    for i in range(0,len(word)-5):\n",
    "        if three_consecutive(word[i:i+6]):\n",
    "            return True\n",
    "    return False\n",
    "def three_consecutive(six_letters):\n",
    "    \"\"\"\n",
    "    >>> three_consecutive(\"aabbcc\")\n",
    "    True\n",
    "    >>> three_consecutive(\"aaasdc\")\n",
    "    False\n",
    "    \"\"\"\n",
    "    for i in range(0,3):\n",
    "        if pair_same(six_letters[i*2:(i*2)+2]) == False:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def pair_same(two_letters):\n",
    "    \"\"\"\n",
    "    >>> pair_same (\"aa\")\n",
    "    True\n",
    "    >>> pair_same (\"bc\")\n",
    "    False\n",
    "    \"\"\"\n",
    "    if two_letters[0] == two_letters[1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "doctest.run_docstring_examples(have_three_consecutive_letters, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "word= \"aabBcc\"\n",
    "a = True\n",
    "for i in range(0,3):\n",
    "        if pair_same(word[i*2:(i*2)+2]) == False:\n",
    "            a = False\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bookkeeper\n",
      "bookkeepers\n",
      "bookkeeping\n",
      "bookkeepings\n"
     ]
    }
   ],
   "source": [
    "find_triple_double()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Chapter 13](http://www.greenteapress.com/thinkpython2/html/thinkpython2014.html) Case study: data structure selection\n",
    "\n",
    "The content in this chapter will be helpful for the next mini project on text mining. The exercises build on each other and get more interesting as you go. You should complete as many as your time and interest allows, and bookmark the rest to revisit as you work on MP3.\n",
    "\n",
    " - Section 13.3-4 gives a good example of some techniques for working with files, processing text, and doing some simple analysis. \n",
    " - Section 13.8 and the Markov generation in Exercise 8 can be a lot of fun. \n",
    " - Now that you know a wide range of different data structures, Section 13.9 starts to give some guidance for choosing between them\n",
    " - Section 13.10 explains Allen's \"4 r's\" of debugging strategy\n",
    " \n",
    "This chapter is also excellent preparation for the [Word Frequency Analysis Project Toolbox](https://sd19spring.github.io/toolboxes/word-frequency-analysis) if you're looking for a straightforward toolbox to start on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 13.1\n",
    "\n",
    "Write a function that reads a file and returns its contents split into a list of single word strings. \n",
    "It should break each line into words, strip whitespace and punctuation from the words, and convert them to lowercase.\n",
    "\n",
    "Implementation tips:\n",
    "\n",
    " - Re-use or modify your `get_lines` function\n",
    " - Keep things simple by implementing the transformations step-by-step, possibly using helper functions\n",
    " - Consider using the [string methods](https://docs.python.org/3/library/stdtypes.html#string-methods) `strip`, `replace` and `translate`\n",
    "  ```python\n",
    "  >>> \"banana\".replace('a', 'o')\n",
    "  'bonono'\n",
    "  ```\n",
    " - The string module provides a string named `whitespace`, which contains space, tab, newline, etc., and `punctuation` which contains the punctuation characters.\n",
    " \n",
    "  ```python\n",
    ">>> import string\n",
    ">>> string.punctuation\n",
    "'!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 4, in NoName\n",
      "Failed example:\n",
      "    get_words('WordsTest.txt')\n",
      "Expected nothing\n",
      "Got:\n",
      "    ['hello', 'i', 'am', 'writing', 'this', 'as', 'a', 'test', 'a', 'test', 'to', 'ensure', 'that', 'this', 'code', 'is', 'working', 'properly', 'i', 'hope', 'it', 'works', 'out', 'after', 'all', 'this', 'will', 'be', 'important']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_words (filename):\n",
    "    \"\"\"\n",
    "    >>> get_words('WordsTest.txt')\n",
    "    ['hello', 'i', 'am', 'writing', 'this', 'as', 'a', 'test', 'a', 'test', 'to', 'ensure', 'that', 'this', 'code', 'is', 'working', 'properly', 'i', 'hope', 'it', 'works', 'out', 'after', 'all', 'this', 'will', 'be', 'important']\n",
    "    \"\"\"\n",
    "    list_lines = get_lines(filename)\n",
    "    word_list = []\n",
    "    \n",
    "    for i in range(0,len(list_lines)):\n",
    "        word_list = word_list+ words_from_list(list_lines[i])\n",
    "    return word_list\n",
    "\n",
    "def words_from_list(list):\n",
    "    \"\"\"\n",
    "    >>> words_from_list(\" 'Hello?' I called out, wondering, just ... thinking.\")\n",
    "    ['hello', 'i', 'called', 'out', 'wondering', 'just', 'thinking']\n",
    "    \"\"\"\n",
    "    a = list.split()\n",
    "    clean_word = []\n",
    "    for i in a:\n",
    "        b = i.strip(string.whitespace)\n",
    "        stripped = b.strip(string.punctuation)\n",
    "        if stripped.isalpha():\n",
    "            stripped = stripped.lower()\n",
    "            clean_word.append(stripped)\n",
    "    return clean_word\n",
    "\n",
    "doctest.run_docstring_examples(get_words, globals())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chapter 13.2  \n",
    "\n",
    "Go to [Project Gutenberg](http://gutenberg.org) and download your favorite out-of-copyright book in plain text format.\n",
    "\n",
    "Use your function from the previous exercise to read the book you downloaded and break it into individual words. \n",
    "_Note_: for best results, skip over the header information at the beginning of the file.\n",
    "\n",
    "Write a program that can count the total number of words in the book, and the number of times each word is used.\n",
    "_Hint_: You can use a modified version of your `histogram` function from Reading Journal 7.\n",
    "\n",
    "For fun, try comparing different books by different authors, written in different eras. Which author uses the most extensive vocabulary? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 3, in NoName\n",
      "Failed example:\n",
      "    num_words_number_times('WordsTest.txt')\n",
      "Expected nothing\n",
      "Got:\n",
      "    (24, [(3, 'this'), (2, 'test'), (2, 'i'), (2, 'a'), (1, 'writing'), (1, 'works'), (1, 'working'), (1, 'will'), (1, 'to'), (1, 'that'), (1, 'properly'), (1, 'out'), (1, 'it'), (1, 'is'), (1, 'important'), (1, 'hope'), (1, 'hello'), (1, 'ensure'), (1, 'code'), (1, 'be'), (1, 'as'), (1, 'am'), (1, 'all'), (1, 'after')])\n"
     ]
    }
   ],
   "source": [
    "def num_words_number_times(filename):\n",
    "    \"\"\"\n",
    "    >>> num_words_number_times('WordsTest.txt')\n",
    "    \n",
    "    \"\"\"\n",
    "    list_words_repeating = get_words(filename)\n",
    "    d = histogram(list_words_repeating)\n",
    "    list_words_dic = []\n",
    "    for word, frequency in d.items():\n",
    "        list_words_dic.append((frequency, word))\n",
    "    list_words_dic.sort(reverse=True)\n",
    "    return len(list_words_dic), list_words_dic\n",
    "\n",
    "def histogram(list_words):\n",
    "    \"\"\"Return a dictionary that counts occurrences of each word in s.\n",
    "    \n",
    "    Examples:\n",
    "    >>> histogram(['i', 'want','to','see','if','i','can' ])\n",
    "    {'i': 2, 'want': 1, 'to': 1, 'see': 1, 'if': 1, 'can': 1}\n",
    "    \"\"\"\n",
    "    d = dict()\n",
    "    for i in range(0,len(list_words)):\n",
    "        d[list_words[i]] = d.get(list_words[i],0) + 1\n",
    "    return d\n",
    "\n",
    "doctest.run_docstring_examples(num_words_number_times, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
